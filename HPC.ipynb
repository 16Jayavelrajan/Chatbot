{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMW00jV2FwnhczJ8CfokuRd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/16Jayavelrajan/Chatbot/blob/main/HPC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKpybpdlRm7l",
        "outputId": "0611bdfa-4bfa-4bbe-bd85-3f5f4c79687c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,003 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,535 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,962 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [82.7 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,767 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,679 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,692 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,237 kB]\n",
            "Fetched 24.4 MB in 3s (9,490 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-bin is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-bin set to manually installed.\n",
            "openmpi-common is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-common set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y openmpi-bin openmpi-common libopenmpi-dev\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_hello.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv); // Initialize MPI\n",
        "\n",
        "    int world_rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank); // Get process rank\n",
        "\n",
        "    int world_size;\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &world_size); // Get total number of processes\n",
        "\n",
        "    printf(\"Hello from processor %d out of %d processors!\\n\", world_rank, world_size);\n",
        "\n",
        "    MPI_Finalize(); // Finalize MPI\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY_pjHWITgj0",
        "outputId": "141d38f2-df89-4429-ff39-4973f4a7d4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_hello.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_hello mpi_hello.c\n"
      ],
      "metadata": {
        "id": "1tNtgdUITlrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_hello\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAB60njCT2Vh",
        "outputId": "2b537a10-4c18-4877-8003-b2c7c30b9d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from processor 3 out of 4 processors!\n",
            "Hello from processor 0 out of 4 processors!\n",
            "Hello from processor 1 out of 4 processors!\n",
            "Hello from processor 2 out of 4 processors!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_send_recv.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    if (rank == 0) {\n",
        "        int data = 42;\n",
        "        MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
        "        printf(\"Process 0 sent %d to Process 1\\n\", data);\n",
        "    }\n",
        "    else if (rank == 1) {\n",
        "        int received_data;\n",
        "        MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "        printf(\"Process 1 received %d from Process 0\\n\", received_data);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqIilTnbUEUV",
        "outputId": "d5fe5003-2da6-490c-b93b-d409e1955546"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting mpi_send_recv.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_send_recv mpi_send_recv.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 2 ./mpi_send_recv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V-KPzvlUZ5S",
        "outputId": "b98d5b49-e614-4561-d95e-c65572d5f86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0 sent 42 to Process 1\n",
            "Process 1 received 42 from Process 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_bsend.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    int buffer_size = MPI_BSEND_OVERHEAD + sizeof(int);\n",
        "    void* buffer = malloc(buffer_size);\n",
        "    MPI_Buffer_attach(buffer, buffer_size);\n",
        "\n",
        "    if (rank == 0) {\n",
        "        int data = 42;\n",
        "        printf(\"Process 0: Sending %d to Process 1 using MPI_Bsend\\n\", data);\n",
        "        MPI_Bsend(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
        "    }\n",
        "    else if (rank == 1) {\n",
        "        int received_data;\n",
        "        MPI_Recv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "        printf(\"Process 1: Received %d from Process 0\\n\", received_data);\n",
        "    }\n",
        "\n",
        "    MPI_Buffer_detach(&buffer, &buffer_size);\n",
        "    free(buffer);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHSjbCQJUdA5",
        "outputId": "86e40b80-95ba-4846-8865-945b28db0677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_bsend.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_bsend mpi_bsend.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 2 ./mpi_bsend\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcV6xKGOVBGw",
        "outputId": "947ad318-ba69-4f00-a592-1c0d566408f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0: Sending 42 to Process 1 using MPI_Bsend\n",
            "Process 1: Received 42 from Process 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_nonblocking.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    MPI_Request request;\n",
        "    MPI_Status status;\n",
        "\n",
        "    if (rank == 0) {\n",
        "        int data = 42;\n",
        "        printf(\"Process 0: Sending %d to Process 1 (Non-blocking)\\n\", data);\n",
        "        MPI_Isend(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &request);\n",
        "        MPI_Wait(&request, &status);  // Ensuring completion before exit\n",
        "    }\n",
        "    else if (rank == 1) {\n",
        "        int received_data;\n",
        "        MPI_Irecv(&received_data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &request);\n",
        "        MPI_Wait(&request, &status);  // Ensure the message is received before printing\n",
        "        printf(\"Process 1: Received %d from Process 0 (Non-blocking)\\n\", received_data);\n",
        "    }\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXAAesUIVEkK",
        "outputId": "6cf60b99-1b49-4361-efdd-1a7a4e268c4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_nonblocking.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_nonblocking mpi_nonblocking.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 2 ./mpi_nonblocking\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNP2xepnVRHW",
        "outputId": "be92e177-6780-4404-9835-4e0c32edc2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0: Sending 42 to Process 1 (Non-blocking)\n",
            "Process 1: Received 42 from Process 0 (Non-blocking)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_init_finalize.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    // Step 1: Initialize MPI\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    // Step 2: Get total number of processes\n",
        "    int size;\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    // Step 3: Get process rank\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    // Step 4: Print process details\n",
        "    printf(\"Hello from process %d out of %d!\\n\", rank, size);\n",
        "\n",
        "    // Step 5: Finalize MPI\n",
        "    MPI_Finalize();\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "QgBNbsc1VWCt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf7e84d-3bbf-4914-c1df-2ffa08bb8022"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_init_finalize.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_init_finalize mpi_init_finalize.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_init_finalize\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qU7U2xWMQty",
        "outputId": "442c1785-0063-4fc7-9e07-e2d905c74721"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from process 1 out of 4!\n",
            "Hello from process 3 out of 4!\n",
            "Hello from process 2 out of 4!\n",
            "Hello from process 0 out of 4!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_deadlock_avoid.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    int data = 42;\n",
        "\n",
        "    if (rank == 0) {\n",
        "        MPI_Send(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);\n",
        "        MPI_Recv(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "    }\n",
        "    else if (rank == 1) {\n",
        "        MPI_Recv(&data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);\n",
        "        MPI_Send(&data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD);\n",
        "    }\n",
        "\n",
        "    printf(\"Process %d: Communication successful\\n\", rank);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYHEnMTtMUXT",
        "outputId": "9f2bcdd0-f1f8-4f52-9756-c78a178b9305"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_deadlock_avoid.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_nonblocking_deadlock_avoid.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    int data = 42;\n",
        "    MPI_Request request;\n",
        "\n",
        "    if (rank == 0) {\n",
        "        MPI_Isend(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &request);\n",
        "        MPI_Irecv(&data, 1, MPI_INT, 1, 0, MPI_COMM_WORLD, &request);\n",
        "        MPI_Wait(&request, MPI_STATUS_IGNORE);\n",
        "    }\n",
        "    else if (rank == 1) {\n",
        "        MPI_Isend(&data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &request);\n",
        "        MPI_Irecv(&data, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, &request);\n",
        "        MPI_Wait(&request, MPI_STATUS_IGNORE);\n",
        "    }\n",
        "\n",
        "    printf(\"Process %d: Communication successful (Non-blocking)\\n\", rank);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tyvcBkSMfTX",
        "outputId": "8e8c5738-e3de-4564-feee-a3112f3cafff"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_nonblocking_deadlock_avoid.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_deadlock_avoid mpi_deadlock_avoid.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 2 ./mpi_deadlock_avoid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFGBLro2MjIW",
        "outputId": "6697a653-acd1-4ce8-92b1-c22274a9a175"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 1: Communication successful\n",
            "Process 0: Communication successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_nonblocking_deadlock_avoid mpi_nonblocking_deadlock_avoid.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 2 ./mpi_nonblocking_deadlock_avoid\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8Pa8-5vMlXm",
        "outputId": "c41c98f1-0a9a-4cf4-be0e-7519b8fa8c15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0: Communication successful (Non-blocking)\n",
            "Process 1: Communication successful (Non-blocking)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_cartesian.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank, size;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    // Define a 2D grid of (rows x cols)\n",
        "    int dims[2] = {2, 2};  // 2x2 grid (must match the number of processes)\n",
        "    int periods[2] = {0, 0}; // No wraparound\n",
        "    int coords[2];\n",
        "    MPI_Comm cart_comm;\n",
        "\n",
        "    // Create Cartesian topology\n",
        "    MPI_Cart_create(MPI_COMM_WORLD, 2, dims, periods, 0, &cart_comm);\n",
        "\n",
        "    // Get Cartesian coordinates of the current process\n",
        "    MPI_Cart_coords(cart_comm, rank, 2, coords);\n",
        "\n",
        "    printf(\"Process %d has Cartesian coordinates (%d, %d)\\n\", rank, coords[0], coords[1]);\n",
        "\n",
        "    // Find neighboring ranks\n",
        "    int left, right, up, down;\n",
        "    MPI_Cart_shift(cart_comm, 0, 1, &up, &down);\n",
        "    MPI_Cart_shift(cart_comm, 1, 1, &left, &right);\n",
        "\n",
        "    printf(\"Process %d (Coords %d,%d) - Left: %d, Right: %d, Up: %d, Down: %d\\n\",\n",
        "           rank, coords[0], coords[1], left, right, up, down);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4r5wugMMnOu",
        "outputId": "896e9d47-ee01-4721-cdfd-7671c224e9b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_cartesian.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_cartesian mpi_cartesian.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_cartesian\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD0rv2KNMxrG",
        "outputId": "e9eb3f14-6193-4fb1-9e24-1bd95f76549a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0 has Cartesian coordinates (0, 0)\n",
            "Process 2 has Cartesian coordinates (1, 0)\n",
            "Process 2 (Coords 1,0) - Left: -2, Right: 3, Up: 0, Down: -2\n",
            "Process 0 (Coords 0,0) - Left: -2, Right: 1, Up: -2, Down: 2\n",
            "Process 1 has Cartesian coordinates (0, 1)\n",
            "Process 1 (Coords 0,1) - Left: 0, Right: -2, Up: -2, Down: 3\n",
            "Process 3 has Cartesian coordinates (1, 1)\n",
            "Process 3 (Coords 1,1) - Left: 2, Right: -2, Up: 1, Down: -2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_bcast.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    int data;\n",
        "    if (rank == 0) {\n",
        "        data = 100; // Root process sets the data\n",
        "        printf(\"Process 0 broadcasting data: %d\\n\", data);\n",
        "    }\n",
        "\n",
        "    MPI_Bcast(&data, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
        "    printf(\"Process %d received data: %d\\n\", rank, data);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmvxffL6M04s",
        "outputId": "b6c564c4-aed9-4a0c-9864-1da8f55831aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_bcast.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_bcast mpi_bcast.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_bcast\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g4yor23NBgy",
        "outputId": "361a8654-ff51-4211-f3c1-90321e85640a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0 broadcasting data: 100\n",
            "Process 0 received data: 100\n",
            "Process 2 received data: 100\n",
            "Process 1 received data: 100\n",
            "Process 3 received data: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_scan.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank, size;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "    MPI_Comm_size(MPI_COMM_WORLD, &size);\n",
        "\n",
        "    int local_value = rank + 1; // Each process has a unique value\n",
        "    int prefix_sum;\n",
        "\n",
        "    MPI_Scan(&local_value, &prefix_sum, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);\n",
        "\n",
        "    printf(\"Process %d: Prefix sum = %d\\n\", rank, prefix_sum);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7ZWM1IDNHIA",
        "outputId": "9069dbc3-4207-4224-d7ed-009675b7a011"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_scan.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_scan mpi_scan.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_scan\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amnG0MeAR5sp",
        "outputId": "cab71001-a551-401b-9b05-f99cd9f746da"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0: Prefix sum = 1\n",
            "Process 1: Prefix sum = 3\n",
            "Process 2: Prefix sum = 6\n",
            "Process 3: Prefix sum = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile mpi_barrier.c\n",
        "#include <mpi.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "int main(int argc, char** argv) {\n",
        "    MPI_Init(&argc, &argv);\n",
        "\n",
        "    int rank;\n",
        "    MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
        "\n",
        "    printf(\"Process %d before barrier\\n\", rank);\n",
        "    MPI_Barrier(MPI_COMM_WORLD);\n",
        "    printf(\"Process %d after barrier\\n\", rank);\n",
        "\n",
        "    MPI_Finalize();\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igIXd_DLSPrk",
        "outputId": "603cf5ae-6639-41d4-de18-7af91c14d4ce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing mpi_barrier.c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mpicc -o mpi_barrier mpi_barrier.c\n",
        "!mpirun --allow-run-as-root --oversubscribe -np 4 ./mpi_barrier\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYNAtAHPSQxP",
        "outputId": "1f1ca185-9d61-41b4-bf32-698c621e7038"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Process 0 before barrier\n",
            "Process 2 before barrier\n",
            "Process 1 before barrier\n",
            "Process 3 before barrier\n",
            "Process 0 after barrier\n",
            "Process 1 after barrier\n",
            "Process 3 after barrier\n",
            "Process 2 after barrier\n"
          ]
        }
      ]
    }
  ]
}